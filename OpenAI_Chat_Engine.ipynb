{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4d3e1610-942d-458e-8379-ebb1fe88ac2c",
      "metadata": {
        "id": "4d3e1610-942d-458e-8379-ebb1fe88ac2c"
      },
      "source": [
        "# Chat Engine - OpenAI Agent Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bacff25a",
      "metadata": {
        "id": "bacff25a"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c1c82b",
      "metadata": {
        "id": "e8c1c82b"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ad2c64",
      "metadata": {
        "id": "f4ad2c64",
        "outputId": "adb60c90-3224-4fc6-8515-448394ba64e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-11-20 14:52:58--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75042 (73K) [text/plain]\n",
            "Saving to: ‘data/paul_graham/paul_graham_essay.txt’\n",
            "\n",
            "data/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-11-20 14:52:58 (2.86 MB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75042/75042]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p 'data/essay/'\n",
        "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/essay/paul_graham_essay.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "941f4d3a-b84c-409d-b371-85c33ab7b68f",
      "metadata": {
        "id": "941f4d3a-b84c-409d-b371-85c33ab7b68f"
      },
      "source": [
        "Load data and build index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a258574-a4d1-42cc-9f1a-bc6f5d4c6a37",
      "metadata": {
        "id": "4a258574-a4d1-42cc-9f1a-bc6f5d4c6a37"
      },
      "outputs": [],
      "source": [
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.llms import OpenAI\n",
        "\n",
        "# Necessary to use the latest OpenAI models that support function calling API\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    llm=OpenAI(model=\"gpt-3.5-turbo-0613\")\n",
        ")\n",
        "data = SimpleDirectoryReader(input_dir=\"../data/essay/\").load_data()\n",
        "index = VectorStoreIndex.from_documents(data, service_context=service_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e0dc626-c877-422f-913a-afd3d3c8cdc8",
      "metadata": {
        "id": "9e0dc626-c877-422f-913a-afd3d3c8cdc8"
      },
      "source": [
        "Configure chat engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37717d64-851d-46c2-b64c-2f5efaaa37f9",
      "metadata": {
        "id": "37717d64-851d-46c2-b64c-2f5efaaa37f9"
      },
      "outputs": [],
      "source": [
        "chat_engine = index.as_chat_engine(chat_mode=\"openai\", verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5b86747-22ca-4626-9df7-ff123ac57883",
      "metadata": {
        "id": "d5b86747-22ca-4626-9df7-ff123ac57883"
      },
      "source": [
        "Chat with your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f09367b-375a-47d3-b0b4-0753b52d834d",
      "metadata": {
        "id": "4f09367b-375a-47d3-b0b4-0753b52d834d",
        "outputId": "59c30a8e-fd48-4d9e-f405-c8e63bc11174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STARTING TURN 1\n",
            "---------------\n",
            "\n",
            "Hello! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "response = chat_engine.chat(\"Hi\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b4b6686-21cd-4974-b767-4ebad4cefb36",
      "metadata": {
        "id": "5b4b6686-21cd-4974-b767-4ebad4cefb36",
        "outputId": "9fe070fd-79fc-413c-a702-f68d12ad45cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STARTING TURN 1\n",
            "---------------\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: query_engine_tool with args: {\n",
            "  \"input\": \"Who did Paul Graham hand over YC to?\"\n",
            "}\n",
            "Got output: Paul Graham handed over YC to Sam Altman.\n",
            "========================\n",
            "\n",
            "STARTING TURN 2\n",
            "---------------\n",
            "\n",
            "Paul Graham handed over Y Combinator (YC) to Sam Altman.\n"
          ]
        }
      ],
      "source": [
        "response = chat_engine.chat(\n",
        "    \"Use the tool to answer: Who did Paul Graham hand over YC to?\"\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "774ad72e-8d9d-48c4-b50b-9eac3b21839e",
      "metadata": {
        "id": "774ad72e-8d9d-48c4-b50b-9eac3b21839e",
        "outputId": "7e2f9a41-deef-4fe6-f94a-16f3ce22fe2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STARTING TURN 1\n",
            "---------------\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: query_engine_tool with args: {\n",
            "  \"input\": \"Who did Paul Graham hand over YC to?\"\n",
            "}\n",
            "Got output: Paul Graham handed over YC to Sam Altman.\n",
            "========================\n",
            "\n",
            "STARTING TURN 2\n",
            "---------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = chat_engine.stream_chat(\n",
        "    \"Use the tool to answer: Who did Paul Graham hand over YC to?\"\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff69f4d8-4c58-46ae-8229-d18d97d31c43",
      "metadata": {
        "id": "ff69f4d8-4c58-46ae-8229-d18d97d31c43"
      },
      "source": [
        "### Force chat engine to query the index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f57c745b-8bda-40fe-875e-f560a9a2dc0b",
      "metadata": {
        "id": "f57c745b-8bda-40fe-875e-f560a9a2dc0b",
        "outputId": "d72d09cf-6c35-43d5-fc18-3a8c9800256c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STARTING TURN 1\n",
            "---------------\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: query_engine_tool with args: {\n",
            "  \"input\": \"What did Paul Graham do growing up?\"\n",
            "}\n",
            "Got output: Growing up, Paul Graham worked on writing and programming. He wrote short stories and also tried his hand at programming on the IBM 1401 computer that his school district had. He later got a microcomputer, a TRS-80, and started programming more extensively, writing simple games and even a word processor.\n",
            "========================\n",
            "\n",
            "STARTING TURN 2\n",
            "---------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = chat_engine.chat(\n",
        "    \"What did Paul Graham do growing up?\", tool_choice=\"query_engine_tool\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67dccf41-9d60-464e-b0e4-f3444e9fa2fe",
      "metadata": {
        "id": "67dccf41-9d60-464e-b0e4-f3444e9fa2fe",
        "outputId": "e98026f6-12aa-44e2-98f6-0756ed334732"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Growing up, Paul Graham worked on writing and programming. He wrote short stories and also tried his hand at programming on the IBM 1401 computer that his school district had. He later got a microcomputer, a TRS-80, and started programming more extensively, writing simple games and even a word processor.\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}